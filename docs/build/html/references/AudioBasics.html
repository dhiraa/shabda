

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Audio Basics &mdash; shabda  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Related Work" href="References.html" />
    <link rel="prev" title="About" href="../about.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> shabda
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">About</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Audio Basics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#reading-audio-files">Reading Audio Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="#audio-features">Audio Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#introduction-to-mfcc">Introduction to MFCC</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fft-stft-cheat-sheet">FFT/STFT Cheat Sheet:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#videos">Videos</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="References.html">Related Work</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../setup/ubuntu.html">Ubuntu Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/intellij.html">IDE Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/projectstructure.html">Shabda Folder Structure</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code/run.html">Executor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/data.html">DatasetFactory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/data.html#audiodatasetbase">AudioDatasetBase</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/data.html#freesoundaudiodataset">FreeSoundAudioDataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/hparams.html">HParams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/models.html">ModelBase</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/models.html#modelsfactory">ModelsFactory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/models.html#classifierbase">ClassifierBase</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">shabda</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Audio Basics</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/references/AudioBasics.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="audio-basics">
<span id="audio-basics"></span><h1>Audio Basics<a class="headerlink" href="#audio-basics" title="Permalink to this headline">¶</a></h1>
<p><strong>What Does the Unit kHz Mean in Digital Music?</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">kHz</span></code> is short for kilohertz, and is a measurement of frequency (cycles per second).
In digital audio, this measurement describes the number of data chunks used per second to represent an analog sound in digital form. These data chunks are known as the sampling rate or sampling frequency.</p>
<p>This definition is often confused with another popular term in digital audio,
called <code class="docutils literal notranslate"><span class="pre">bitrate</span> <span class="pre">(measured</span> <span class="pre">in</span> <span class="pre">kbps)</span></code>. However, the difference between these two terms is that bitrate measures how much is sampled every second (size of the chunks) rather than the number of chunks (frequency).</p>
<p><strong>Note:</strong> kHz is sometimes referred to as sampling rate, sampling interval, or cycles per second.</p>
<p><strong>What is the Mel scale?</strong></p>
<p>The Mel scale relates perceived frequency, or pitch, of a pure tone to its actual measured frequency. Humans are much better at discerning small changes in pitch at low frequencies than they are at high frequencies. Incorporating this scale makes our features match more closely what humans hear.</p>
<p><strong>Audio Features</strong></p>
<ul class="simple">
<li>We start with a speech signal, we’ll assume sampled at 16kHz.</li>
<li>Frame the signal into 20-40 ms frames. 25ms is standard.<ul>
<li>This means the frame length for a 16kHz signal is 0.025*16000 = 400 samples.</li>
<li>Frame step is usually something like 10ms (160 samples), which allows some overlap to the frames.</li>
<li>The first 400 sample frame starts at sample 0, the next 400 sample frame starts at sample 160 etc. until the end of the speech file is reached.</li>
<li>If the speech file does not divide into an even number of frames, pad it with zeros so that it does.</li>
</ul>
</li>
<li>Audio Signal File : 0 to N seconds</li>
<li>Audio Frame : Interval of 20 - 40 ms —&gt; default 25 ms —&gt; 0.025 * 16000 = 400 samples</li>
<li>Frame step : Default 10 ms —&gt; 0.010 * 16000 —&gt; 160 samples<ul>
<li>First sample: 0 to 400 samples</li>
<li>Second sample: 160 to 560 samples etc.,</li>
</ul>
</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>25ms    25ms   25ms   25ms …  Frames  
400     400    400    400  …  Samples/Frame 

|—————|—————|—————|—————|—————|—————|—————|————-|   

|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|—|   

10 10 10 10 … Frame Step
</pre></div>
</div>
<p><strong>Bit-depth = 16:</strong> The amplitude of each sample in the audio is one of 2^16 (=65536) possible values.
<strong>Samplig rate = 44.1 kHz:</strong> Each second in the audio consists of 44100 samples. So, if the duration of the audio file is 3.2 seconds, the audio will consist of 44100*3.2 = 141120 values.</p>
<p>Still dont get it? Consider the audio signal to be a time series sampled at an interval of 25ms with step size of 10ms</p>
<p>Check out this jupyet notebook &#64; https://timsainb.github.io/spectrograms-mfccs-and-inversion-in-python.html</p>
<p>Forked version &#64; https://github.com/dhiraa/python_spectrograms_and_inversion</p>
<p><a class="reference external" href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">Mel Frequency Cepstral Coefficient (MFCC) tutorial</a></p>
<div class="section" id="reading-audio-files">
<span id="reading-audio-files"></span><h2>Reading Audio Files<a class="headerlink" href="#reading-audio-files" title="Permalink to this headline">¶</a></h2>
<p>The audios are <a class="reference external" href="https://en.wikipedia.org/wiki/Audio_bit_depth">Pulse-code modulated</a> with a <a class="reference external" href="https://en.wikipedia.org/wiki/Audio_bit_depth">bit depth</a> of 16 and a <a class="reference external" href="https://en.wikipedia.org/wiki/Sampling_%28signal_processing%29">sampling rate</a> of 44.1 kHz</p>
<p><img alt="16-bit PCM" src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Pcm.svg/500px-Pcm.svg.png" /></p>
<ul class="simple">
<li><strong>Bit-depth = 16</strong>: The amplitude of each sample in the audio is one of 2^16 (=65536) possible values.</li>
<li><strong>Samplig rate = 44.1 kHz</strong>: Each second in the audio consists of 44100 samples. So, if the duration of the audio file is 3.2 seconds, the audio will consist of 44100*3.2 = 141120 values.</li>
</ul>
</div>
<div class="section" id="audio-features">
<span id="audio-features"></span><h2>Audio Features<a class="headerlink" href="#audio-features" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Zero Cross Rate</li>
<li>Energy</li>
<li>Entropy of Energy</li>
<li>Spectral Centroid</li>
<li>Spectral Spread</li>
<li>Spectral Entropy</li>
<li>Spectral Flux</li>
<li>Spectral Roll off</li>
<li>MFCC</li>
<li>Chroma Vector</li>
<li>Chroma Deviation</li>
</ul>
</div>
<div class="section" id="introduction-to-mfcc">
<span id="introduction-to-mfcc"></span><h2>Introduction to MFCC<a class="headerlink" href="#introduction-to-mfcc" title="Permalink to this headline">¶</a></h2>
<p>Before the Deep Learning era, people developed techniques to extract features from audio signals. It turns out that these techniques are still useful. One such technique is computing the MFCC (Mel Frquency Cepstral Coefficients) from the raw audio. Before we jump to MFCC, let’s talk about extracting features from the sound.</p>
<p>If we just want to classify some sound, we should build features that are <strong>speaker independent</strong>. Any feature that only gives information about the speaker (like the pitch of their voice) will not be helpful for classification. In other words, we should extract features that depend on the “content” of the audio rather than the nature of the speaker. Also, a good feature extraction technique should mimic the human speech perception. We don’t hear loudness on a linear scale. If we want to double the perceived loudness of a sound, we have to put 8 times as much energy into it. Instead of a linear scale, our perception system uses a log scale.</p>
<p>Taking these things into account, Davis and Mermelstein came up with MFCC in the 1980’s. MFCC mimics the logarithmic perception of loudness and pitch of human auditory system and tries to eliminate speaker dependent characteristics by excluding the fundamental frequency and their harmonics. The underlying mathematics is quite complicated and we will skip that. For those interested, here is the <a class="reference external" href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">detailed explanation</a>.</p>
<p><img alt="" src="https://openi.nlm.nih.gov/imgs/512/219/3859042/PMC3859042_sensors-13-12929f1.png" /></p>
</div>
<div class="section" id="fft-stft-cheat-sheet">
<span id="fft-stft-cheat-sheet"></span><h2>FFT/STFT Cheat Sheet:<a class="headerlink" href="#fft-stft-cheat-sheet" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><strong>FFT:</strong> Fast Fourier transformA method for computing the discrete Fourier transform of a signal. Its “fastness”
relies on size being a power of 2.</li>
<li><strong>STFT: Short-time Fourier transform</strong>
A method for analyzing a signal whose frequency content is changing over time.
The signal is broken into small, often overlapping frames, and the FFT is computed for
each frame (i.e., the frequency content is assumed not to change within a frame, but
subsequent analysis frames can be compared to understand how the frequency content
changes over time).</li>
<li><strong>IFFT: Inverse Fast Fourier transform</strong>
Takes a spectrum buffer (a complex vector) of N bins and transforms it into N
audio samples.</li>
<li><strong>FFT size:</strong>
The number of samples over which the FFT is computed; also the number of
“bins” that comprise the analysis output.</li>
<li><strong>Bin:</strong>
The content of a bin denotes the magnitude (and phase) of the frequency
corresponding to the bin number. The N bins of an N-sample FFT evenly (linearly)
partition the spectrum from 0Hz to the sample rate. Note that for real signals (including
audio), we can discard the latter half of the bins, using only the bins from 0Hz to the
Nyquist frequency.</li>
<li><strong>Window function:</strong>
Before computing the FFT, the signal is multiplied by a window function. The
simplest window is a rectangular window, which multiplies everything inside the frame
by 1 and everything outside the frame by 0. However, in practice, we choose a smoother
window function that is 1 in the middle of the window and tapers to 0 or near-0 at the
edges. The choice of window depends on the application.</li>
<li><strong>Zero-padding:</strong>
It is common practice to use a smaller window size than FFT size, then “zeropad”
all the samples that lie in between the edges of the window and the edges of the FFT
frame.</li>
<li><strong>Hop size:</strong>
In STFT, you must decide how frequently to perform FFT computations on the
signal. If your FFT size is 512 samples, and you have a hop size of 512 samples, you are
sliding the analysis frame along the signal with no overlap, nor any space between
analyses. If your hop size is 256 samples, you are using 50% overlap. The hop size can be
small (high overlap) if you want to very faithfully recreate the sound using an IFFT, or
very large if you’re only concerned about the spectrum’s or spectral features’ values
every now and then.</li>
</ul>
</div>
<div class="section" id="videos">
<span id="videos"></span><h2>Videos<a class="headerlink" href="#videos" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>https://youtu.be/1RIA9U5oXro</li>
<li>https://youtu.be/PjlIKVnKe8I</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="References.html" class="btn btn-neutral float-right" title="Related Work" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../about.html" class="btn btn-neutral" title="About" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Shabda Team

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>